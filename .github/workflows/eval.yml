name: Skill Evaluations

on:
  workflow_dispatch:

jobs:
  eval:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write

    strategy:
      fail-fast: false
      matrix:
        test:
          - hope-gate-completion
          - hope-soul-planning
          - hope-trace-debugging
          - product-prd-request
          - wordsmith-edit-request

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run Eval - ${{ matrix.test }}
        id: eval
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          plugin_marketplaces: |
            https://github.com/saadshahd/moo.md.git
          plugins: |
            hope@moo.md
            product@moo.md
            wordsmith@moo.md
            founder@moo.md
            career@moo.md
          prompt: |
            You are evaluating skill auto-triggering for the moo.md plugin marketplace.

            ## Instructions
            1. Read eval/cases/skill-triggers/${{ matrix.test }}.yaml
            2. Extract the "prompt" and "expected_behaviors" fields
            3. Process the prompt as if a user sent it (let skills auto-trigger naturally)
            4. Self-evaluate your response against expected behaviors
            5. Return JSON matching the schema with verdict: PASS (all behaviors), PARTIAL (some), FAIL (skill didn't trigger)
          claude_args: '--output-format json --json-schema eval/schema.json'

      - name: Check Verdict
        run: |
          RESULT='${{ steps.eval.outputs.structured_output }}'
          echo "Test: ${{ matrix.test }}"
          echo "$RESULT" | jq .

          VERDICT=$(echo "$RESULT" | jq -r '.verdict')
          if [ "$VERDICT" = "FAIL" ]; then
            echo "::error::Test ${{ matrix.test }} failed"
            echo "Reasoning: $(echo "$RESULT" | jq -r '.reasoning')"
            exit 1
          fi
          echo "âœ“ ${{ matrix.test }}: $VERDICT"
